{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 72, 56, 56])\n",
      "torch.Size([1, 72, 56, 56])\n",
      "torch.Size([1, 120, 28, 28])\n",
      "torch.Size([1, 120, 28, 28])\n",
      "torch.Size([1, 240, 28, 28])\n",
      "torch.Size([1, 200, 14, 14])\n",
      "torch.Size([1, 184, 14, 14])\n",
      "torch.Size([1, 184, 14, 14])\n",
      "torch.Size([1, 480, 14, 14])\n",
      "torch.Size([1, 672, 14, 14])\n",
      "torch.Size([1, 672, 14, 14])\n",
      "torch.Size([1, 960, 7, 7])\n",
      "torch.Size([1, 960, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "import torch\n",
    "\n",
    "x = torch.randn([1, 3, 224, 224])\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "def hook(module, args, output):\n",
    "    print(args[0].shape)\n",
    "\n",
    "for mod in model.modules():\n",
    "    if isinstance(mod, torch.nn.Conv2d) and mod.groups == mod.in_channels:\n",
    "        mod.register_forward_hook(hook)\n",
    "\n",
    "model(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(32, 32, kernel_size=3, padding=1, groups=32, bias=False),\n",
    "    nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    ").cuda()\n",
    "\n",
    "x = torch.randn([1, 32, 64, 64], requires_grad=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinnamkim/flash-fft-conv/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    if param.grad is not None:\n",
    "        param.grad.data.fill_(0.0)\n",
    "\n",
    "y = model(x)\n",
    "y.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_forward\n",
    "\n",
    "n, num_channels, h, w = 32, 16, 112, 112\n",
    "#n, num_channels, h, w = 16, 960, 7, 7\n",
    "n, num_channels, h, w = 32, 240, 28, 28\n",
    "# n = 4\n",
    "# num_channels = 512\n",
    "# h = w = 64\n",
    "\n",
    "depthwise_conv2d = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, groups=num_channels, bias=False).cuda()\n",
    "x = torch.randn([n, num_channels, h, w], requires_grad=False).cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run():\n",
    "    y = depthwise_conv2d(x)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "y = run()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_my():\n",
    "    y = conv2d_forward(x, depthwise_conv2d.weight.contiguous(), 1)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "z = run_my()\n",
    "\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 ms ± 61.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run_my()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 ms ± 8.97 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grad_input': (tensor([[[[-1.1761, -0.4659, -1.0021, -1.1099, -0.4924],\n",
      "          [-1.6424, -0.9335, -1.5599, -0.5499, -0.0767],\n",
      "          [-0.7760, -1.1514,  0.8276, -0.9263, -0.4568],\n",
      "          [ 0.4002, -1.2251, -0.7052, -0.5529, -0.4925],\n",
      "          [-0.2923,  0.1769,  0.2545, -0.1098,  0.0704]],\n",
      "\n",
      "         [[ 0.4894,  0.2689,  0.3237,  0.3378,  0.2755],\n",
      "          [-0.1332,  0.6338,  0.4120,  0.3929,  0.3878],\n",
      "          [ 0.0254,  0.3548,  0.3603,  0.3797,  0.4281],\n",
      "          [ 0.0468,  0.2192,  0.5309,  0.2608,  0.3510],\n",
      "          [-0.0229,  0.1157, -0.0219,  0.2763,  0.2349]]]], device='cuda:0'),), 'grad_output': (tensor([[[[2.3219, 0.4889, 0.7353, 1.4784, 0.8255],\n",
      "          [1.7288, 0.7952, 1.1299, 1.7820, 0.5137],\n",
      "          [0.8228, 4.3713, 0.4083, 0.7533, 0.7121],\n",
      "          [0.5583, 0.4888, 1.1688, 1.1043, 0.5728],\n",
      "          [0.9874, 1.2586, 0.7029, 1.1646, 0.9361]],\n",
      "\n",
      "         [[1.8999, 0.8865, 0.9262, 1.1549, 0.8149],\n",
      "          [1.1085, 1.5337, 1.0881, 1.2519, 0.9353],\n",
      "          [0.9266, 1.2135, 0.9667, 1.4411, 1.2936],\n",
      "          [0.8538, 0.9477, 1.2390, 0.9677, 0.8926],\n",
      "          [0.9165, 0.8303, 0.8421, 1.4025, 0.9742]]]], device='cuda:0'),)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_backward\n",
    "\n",
    "# n, num_channels, h, w = 32, 16, 112, 112\n",
    "#n, num_channels, h, w = 16, 960, 7, 7\n",
    "# n, num_channels, h, w = 32, 240, 28, 28\n",
    "n, num_channels, h, w = 1, 2, 5, 5\n",
    "# n = 4\n",
    "# num_channels = 512\n",
    "# h = w = 64\n",
    "\n",
    "depthwise_conv2d = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, groups=num_channels, bias=False).cuda()\n",
    "x = torch.randn([n, num_channels, h, w], requires_grad=True).cuda()\n",
    "\n",
    "states = {}\n",
    "def log_bwd(module, grad_input, grad_output):\n",
    "    states[\"grad_input\"] = grad_input\n",
    "    states[\"grad_output\"] = grad_output\n",
    "\n",
    "depthwise_conv2d.register_full_backward_hook(log_bwd)\n",
    "\n",
    "y = depthwise_conv2d(x)\n",
    "y.exp().sum().backward()\n",
    "\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grad_input': (tensor([[[[-1.1761, -0.4659, -1.0021, -1.1099, -0.4924],\n",
      "          [-1.6424, -0.9335, -1.5599, -0.5499, -0.0767],\n",
      "          [-0.7760, -1.1514,  0.8276, -0.9263, -0.4568],\n",
      "          [ 0.4002, -1.2251, -0.7052, -0.5529, -0.4925],\n",
      "          [-0.2923,  0.1769,  0.2545, -0.1098,  0.0704]],\n",
      "\n",
      "         [[ 0.4894,  0.2689,  0.3237,  0.3378,  0.2755],\n",
      "          [-0.1332,  0.6338,  0.4120,  0.3929,  0.3878],\n",
      "          [ 0.0254,  0.3548,  0.3603,  0.3797,  0.4281],\n",
      "          [ 0.0468,  0.2192,  0.5309,  0.2608,  0.3510],\n",
      "          [-0.0229,  0.1157, -0.0219,  0.2763,  0.2349]]]], device='cuda:0'),), 'grad_output': (tensor([[[[2.3219, 0.4889, 0.7353, 1.4784, 0.8255],\n",
      "          [1.7288, 0.7952, 1.1299, 1.7820, 0.5137],\n",
      "          [0.8228, 4.3713, 0.4083, 0.7533, 0.7121],\n",
      "          [0.5583, 0.4888, 1.1688, 1.1043, 0.5728],\n",
      "          [0.9874, 1.2586, 0.7029, 1.1646, 0.9361]],\n",
      "\n",
      "         [[1.8999, 0.8865, 0.9262, 1.1549, 0.8149],\n",
      "          [1.1085, 1.5337, 1.0881, 1.2519, 0.9353],\n",
      "          [0.9266, 1.2135, 0.9667, 1.4411, 1.2936],\n",
      "          [0.8538, 0.9477, 1.2390, 0.9677, 0.8926],\n",
      "          [0.9165, 0.8303, 0.8421, 1.4025, 0.9742]]]], device='cuda:0'),)}\n",
      "tensor([[[[-1.1761, -0.4659, -1.0021, -1.1099, -0.4924],\n",
      "          [-1.6424, -0.9335, -1.5599, -0.5499, -0.0767],\n",
      "          [-0.7760, -1.1514,  0.8276, -0.9263, -0.4568],\n",
      "          [ 0.4002, -1.2251, -0.7052, -0.5529, -0.4925],\n",
      "          [-0.2923,  0.1769,  0.2545, -0.1098,  0.0704]],\n",
      "\n",
      "         [[ 0.4894,  0.2689,  0.3237,  0.3378,  0.2755],\n",
      "          [-0.1332,  0.6338,  0.4120,  0.3929,  0.3878],\n",
      "          [ 0.0254,  0.3548,  0.3603,  0.3797,  0.4281],\n",
      "          [ 0.0468,  0.2192,  0.5309,  0.2608,  0.3510],\n",
      "          [-0.0229,  0.1157, -0.0219,  0.2763,  0.2349]]]], device='cuda:0')\n",
      "{'grad_input': (tensor([[[[-1.1761, -0.4659, -1.0021, -1.1099, -0.4924],\n",
      "          [-1.6424, -0.9335, -1.5599, -0.5499, -0.0767],\n",
      "          [-0.7760, -1.1514,  0.8276, -0.9263, -0.4568],\n",
      "          [ 0.4002, -1.2251, -0.7052, -0.5529, -0.4925],\n",
      "          [-0.2923,  0.1769,  0.2545, -0.1098,  0.0704]],\n",
      "\n",
      "         [[ 0.4894,  0.2689,  0.3237,  0.3378,  0.2755],\n",
      "          [-0.1332,  0.6338,  0.4120,  0.3929,  0.3878],\n",
      "          [ 0.0254,  0.3548,  0.3603,  0.3797,  0.4281],\n",
      "          [ 0.0468,  0.2192,  0.5309,  0.2608,  0.3510],\n",
      "          [-0.0229,  0.1157, -0.0219,  0.2763,  0.2349]]]], device='cuda:0'),), 'grad_output': (tensor([[[[2.3219, 0.4889, 0.7353, 1.4784, 0.8255],\n",
      "          [1.7288, 0.7952, 1.1299, 1.7820, 0.5137],\n",
      "          [0.8228, 4.3713, 0.4083, 0.7533, 0.7121],\n",
      "          [0.5583, 0.4888, 1.1688, 1.1043, 0.5728],\n",
      "          [0.9874, 1.2586, 0.7029, 1.1646, 0.9361]],\n",
      "\n",
      "         [[1.8999, 0.8865, 0.9262, 1.1549, 0.8149],\n",
      "          [1.1085, 1.5337, 1.0881, 1.2519, 0.9353],\n",
      "          [0.9266, 1.2135, 0.9667, 1.4411, 1.2936],\n",
      "          [0.8538, 0.9477, 1.2390, 0.9677, 0.8926],\n",
      "          [0.9165, 0.8303, 0.8421, 1.4025, 0.9742]]]], device='cuda:0'),)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(states)\n",
    "with torch.no_grad():\n",
    "    din, dweights = conv2d_backward(states[\"grad_output\"][0], x.clone(), depthwise_conv2d.weight, 1)\n",
    "print(din)\n",
    "print(states)\n",
    "# print(din.shape)\n",
    "# print(dweights)\n",
    "# print(dweights.shape)\n",
    "torch.allclose(states[\"grad_input\"][0], din)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.3339, 0.6068, 1.4437, 0.4591, 3.2536],\n",
       "          [0.4609, 0.8319, 1.2438, 1.3593, 0.4581],\n",
       "          [3.2788, 1.1048, 1.0025, 0.9150, 0.8091],\n",
       "          [0.5265, 2.7995, 1.8639, 1.1154, 1.9408],\n",
       "          [1.0752, 0.4621, 0.7071, 0.9627, 0.6054]],\n",
       "\n",
       "         [[0.9014, 2.2644, 1.0638, 0.7618, 1.0463],\n",
       "          [0.4676, 3.2272, 1.1820, 0.8296, 3.7058],\n",
       "          [0.9902, 1.6993, 0.2760, 1.1363, 3.5201],\n",
       "          [0.7246, 0.8807, 0.8306, 1.5082, 1.4903],\n",
       "          [0.9297, 2.2455, 1.0649, 0.8699, 1.2829]]]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[\"grad_output\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.3243,  0.2552,  0.0164,  0.2652, -0.7573],\n",
       "           [ 0.9317,  0.1859,  0.2556,  0.3482,  1.0515],\n",
       "           [-0.5501,  1.2759,  0.7390,  0.3441,  0.0424],\n",
       "           [ 0.8952, -1.3240,  0.2384,  0.2251, -0.2865],\n",
       "           [ 0.2867,  0.9382, -0.4277, -0.1551,  0.1596]],\n",
       " \n",
       "          [[ 0.7385, -0.4478, -0.8459, -0.0750, -0.9847],\n",
       "           [ 1.1138, -0.2448, -0.7152,  0.7494, -0.9785],\n",
       "           [ 1.1503, -0.8641, -0.2171,  1.4930, -1.4552],\n",
       "           [ 0.3670, -0.7512,  0.2272,  0.7006, -1.5908],\n",
       "           [ 0.7140,  0.2325, -0.1341,  0.1210, -0.4547]]]], device='cuda:0'),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[\"grad_input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
