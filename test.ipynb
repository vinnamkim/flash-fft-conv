{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 112, 112])\n",
      "torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 72, 56, 56])\n",
      "torch.Size([1, 72, 56, 56])\n",
      "torch.Size([1, 120, 28, 28])\n",
      "torch.Size([1, 120, 28, 28])\n",
      "torch.Size([1, 240, 28, 28])\n",
      "torch.Size([1, 200, 14, 14])\n",
      "torch.Size([1, 184, 14, 14])\n",
      "torch.Size([1, 184, 14, 14])\n",
      "torch.Size([1, 480, 14, 14])\n",
      "torch.Size([1, 672, 14, 14])\n",
      "torch.Size([1, 672, 14, 14])\n",
      "torch.Size([1, 960, 7, 7])\n",
      "torch.Size([1, 960, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "import torch\n",
    "\n",
    "x = torch.randn([1, 3, 224, 224])\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "def hook(module, args, output):\n",
    "    print(args[0].shape)\n",
    "\n",
    "for mod in model.modules():\n",
    "    if isinstance(mod, torch.nn.Conv2d) and mod.groups == mod.in_channels:\n",
    "        mod.register_forward_hook(hook)\n",
    "\n",
    "model(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(32, 32, kernel_size=3, padding=1, groups=32, bias=False),\n",
    "    nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    ").cuda()\n",
    "\n",
    "x = torch.randn([1, 32, 64, 64], requires_grad=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinnamkim/flash-fft-conv/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    if param.grad is not None:\n",
    "        param.grad.data.fill_(0.0)\n",
    "\n",
    "y = model(x)\n",
    "y.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_forward\n",
    "\n",
    "n, num_channels, h, w = 32, 16, 112, 112\n",
    "#n, num_channels, h, w = 16, 960, 7, 7\n",
    "n, num_channels, h, w = 32, 240, 28, 28\n",
    "# n = 4\n",
    "# num_channels = 512\n",
    "# h = w = 64\n",
    "\n",
    "depthwise_conv2d = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, groups=num_channels, bias=False).cuda()\n",
    "x = torch.randn([n, num_channels, h, w], requires_grad=False).cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run():\n",
    "    y = depthwise_conv2d(x)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "y = run()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_my():\n",
    "    y = conv2d_forward(x, depthwise_conv2d.weight.contiguous(), 1)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "z = run_my()\n",
    "\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 ms ± 61.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run_my()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 ms ± 8.97 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 32, 32]),\n",
       " torch.Size([1, 2, 32, 32]),\n",
       " torch.Size([2, 1, 3, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, z.shape, depthwise_conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6789e-04, -2.5931e-04, -1.9989e-04],\n",
       "          [-1.5090e-04, -2.3825e-04, -1.7833e-04],\n",
       "          [-1.2129e-04, -2.0130e-04, -1.4132e-04]]],\n",
       "\n",
       "\n",
       "        [[[-1.0133e-04, -9.8267e-05, -1.1907e-04],\n",
       "          [-1.1414e-04, -1.1293e-04, -1.3485e-04],\n",
       "          [-1.3128e-04, -1.3289e-04, -1.5608e-04]]],\n",
       "\n",
       "\n",
       "        [[[-1.8379e-04, -1.7843e-04, -1.6717e-04],\n",
       "          [-1.5581e-04, -1.5098e-04, -1.3873e-04],\n",
       "          [-1.5948e-04, -1.5850e-04, -1.4639e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4354e-05,  6.8785e-05,  8.9805e-05],\n",
       "          [ 6.5355e-05,  6.5105e-05,  8.5797e-05],\n",
       "          [ 5.0063e-05,  4.8304e-05,  6.6207e-05]]],\n",
       "\n",
       "\n",
       "        [[[-1.2251e-04, -6.9850e-05, -5.1950e-05],\n",
       "          [-1.2614e-04, -7.2298e-05, -4.9813e-05],\n",
       "          [-5.1994e-05, -1.2274e-06,  1.7884e-05]]],\n",
       "\n",
       "\n",
       "        [[[-1.0487e-04, -2.2397e-04, -4.0430e-04],\n",
       "          [-5.0163e-05, -1.5823e-04, -3.2890e-04],\n",
       "          [-1.5510e-05, -1.2504e-04, -3.0435e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 8.6366e-05,  8.0099e-05,  9.6377e-05],\n",
       "          [ 7.7161e-05,  7.0968e-05,  8.6710e-05],\n",
       "          [ 8.9086e-05,  8.5875e-05,  9.9772e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 5.7339e-05,  4.8798e-05,  5.8920e-05],\n",
       "          [ 5.7383e-05,  5.1195e-05,  6.2656e-05],\n",
       "          [ 3.2739e-05,  2.7533e-05,  4.2601e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 4.7977e-05,  7.4892e-05,  1.0373e-04],\n",
       "          [ 4.0858e-05,  6.8093e-05,  9.8554e-05],\n",
       "          [ 4.1889e-05,  7.0740e-05,  1.0320e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.8050e-04, -4.4609e-04, -4.1381e-04],\n",
       "          [-4.3067e-04, -4.8911e-04, -4.5333e-04],\n",
       "          [-3.5235e-04, -4.0375e-04, -3.6544e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7758e-04,  2.6786e-04,  2.5368e-04],\n",
       "          [ 2.8722e-04,  2.7528e-04,  2.6351e-04],\n",
       "          [ 2.6936e-04,  2.6437e-04,  2.4873e-04]]],\n",
       "\n",
       "\n",
       "        [[[-8.8446e-05, -8.2608e-05, -6.5358e-05],\n",
       "          [-8.4923e-05, -8.0168e-05, -6.3410e-05],\n",
       "          [-9.6896e-05, -9.2457e-05, -7.5060e-05]]],\n",
       "\n",
       "\n",
       "        [[[-2.4373e-04, -2.6684e-04, -2.9297e-04],\n",
       "          [-2.2044e-04, -2.3927e-04, -2.6268e-04],\n",
       "          [-1.8252e-04, -2.0296e-04, -2.2754e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4446e-04,  3.9581e-04,  3.4748e-04],\n",
       "          [ 3.2374e-04,  3.7057e-04,  3.2344e-04],\n",
       "          [ 3.1224e-04,  3.4893e-04,  3.0680e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.1228e-04, -3.1669e-04, -2.9762e-04],\n",
       "          [-3.1085e-04, -3.1572e-04, -2.9265e-04],\n",
       "          [-3.0509e-04, -3.0574e-04, -2.8065e-04]]],\n",
       "\n",
       "\n",
       "        [[[-4.7478e-05, -2.8315e-05,  5.0908e-05],\n",
       "          [-6.7176e-05, -5.5691e-05,  2.1601e-05],\n",
       "          [-6.1418e-05, -5.7061e-05, -3.2677e-06]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9713e-05,  2.3166e-05,  2.0513e-05],\n",
       "          [ 1.9782e-05,  2.3379e-05,  2.1024e-05],\n",
       "          [ 1.7343e-05,  2.0651e-05,  1.8482e-05]]],\n",
       "\n",
       "\n",
       "        [[[-2.9712e-05, -1.2894e-06,  2.9389e-05],\n",
       "          [-1.0317e-05,  1.8861e-05,  4.7285e-05],\n",
       "          [-5.0865e-05, -2.0093e-05,  8.2024e-06]]],\n",
       "\n",
       "\n",
       "        [[[ 5.9192e-05,  7.5653e-05,  7.4662e-05],\n",
       "          [ 7.0794e-05,  9.0541e-05,  8.4408e-05],\n",
       "          [ 8.9360e-05,  1.0681e-04,  9.9288e-05]]],\n",
       "\n",
       "\n",
       "        [[[-4.8493e-05, -4.9265e-05, -5.2592e-05],\n",
       "          [-5.0633e-05, -5.0892e-05, -5.4096e-05],\n",
       "          [-4.6821e-05, -4.7260e-05, -5.1166e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 6.1633e-05,  5.8095e-05,  4.9026e-05],\n",
       "          [ 5.3137e-05,  4.9517e-05,  3.8002e-05],\n",
       "          [ 6.3881e-05,  6.0216e-05,  4.7486e-05]]],\n",
       "\n",
       "\n",
       "        [[[-4.3143e-04, -5.4810e-04, -5.7859e-04],\n",
       "          [-3.8849e-04, -5.0759e-04, -5.3894e-04],\n",
       "          [-3.8348e-04, -4.9678e-04, -5.4171e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.2905e-04, -3.7030e-04, -4.4060e-04],\n",
       "          [-3.7914e-04, -4.3192e-04, -4.9379e-04],\n",
       "          [-3.9030e-04, -4.4427e-04, -5.0558e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9435e-06, -9.9810e-06, -4.5999e-05],\n",
       "          [-4.9442e-06, -2.7861e-05, -6.8445e-05],\n",
       "          [-3.5795e-05, -5.3899e-05, -1.0087e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 4.1825e-05,  5.9374e-05,  1.5028e-05],\n",
       "          [ 6.1668e-05,  8.1073e-05,  3.9390e-05],\n",
       "          [ 8.3311e-05,  1.0923e-04,  7.0571e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 8.9187e-05,  9.2861e-05,  8.8101e-05],\n",
       "          [ 9.5932e-05,  9.8988e-05,  9.2599e-05],\n",
       "          [ 8.5823e-05,  8.8114e-05,  8.1228e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0958e-04,  3.2713e-04,  3.2201e-04],\n",
       "          [ 3.5012e-04,  3.6913e-04,  3.6230e-04],\n",
       "          [ 3.5173e-04,  3.6946e-04,  3.6274e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5535e-04,  1.5704e-04,  1.2656e-04],\n",
       "          [ 1.3486e-04,  1.4183e-04,  1.1491e-04],\n",
       "          [ 1.6769e-04,  1.7157e-04,  1.4072e-04]]],\n",
       "\n",
       "\n",
       "        [[[-6.6255e-05, -7.7588e-05, -6.2534e-05],\n",
       "          [-6.9782e-05, -7.9370e-05, -6.5996e-05],\n",
       "          [-7.1777e-05, -8.0056e-05, -6.4425e-05]]],\n",
       "\n",
       "\n",
       "        [[[-1.5944e-04, -1.7778e-04, -1.9783e-04],\n",
       "          [-1.5542e-04, -1.7630e-04, -1.9654e-04],\n",
       "          [-1.6527e-04, -1.8586e-04, -2.0442e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2625e-04,  1.4893e-04,  4.8757e-05],\n",
       "          [ 1.2779e-04,  1.5568e-04,  5.9980e-05],\n",
       "          [ 1.2101e-04,  1.4911e-04,  5.7415e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0770e-04,  2.1770e-04,  1.7681e-04],\n",
       "          [ 3.0971e-04,  2.1807e-04,  1.6938e-04],\n",
       "          [ 4.2283e-04,  3.3003e-04,  2.7517e-04]]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model.parameters())).grad.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
