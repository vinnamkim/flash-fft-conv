{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add problem size: torch.Size([1, 16, 112, 112, 3, 3])\n",
      "Add problem size: torch.Size([1, 64, 112, 112, 3, 3])\n",
      "Add problem size: torch.Size([1, 72, 56, 56, 3, 3])\n",
      "Add problem size: torch.Size([1, 72, 56, 56, 5, 5])\n",
      "Add problem size: torch.Size([1, 120, 28, 28, 5, 5])\n",
      "Add problem size: torch.Size([1, 120, 28, 28, 5, 5])\n",
      "Add problem size: torch.Size([1, 240, 28, 28, 3, 3])\n",
      "Add problem size: torch.Size([1, 200, 14, 14, 3, 3])\n",
      "Add problem size: torch.Size([1, 184, 14, 14, 3, 3])\n",
      "Add problem size: torch.Size([1, 184, 14, 14, 3, 3])\n",
      "Add problem size: torch.Size([1, 480, 14, 14, 3, 3])\n",
      "Add problem size: torch.Size([1, 672, 14, 14, 3, 3])\n",
      "Add problem size: torch.Size([1, 672, 14, 14, 5, 5])\n",
      "Add problem size: torch.Size([1, 960, 7, 7, 5, 5])\n",
      "Add problem size: torch.Size([1, 960, 7, 7, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "x = torch.randn([1, 3, 224, 224])\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "def hook(module, args, output, problem_sizes):\n",
    "    p_size = args[0].shape + (module.kernel_size)\n",
    "    print(\"Add problem size:\", p_size)\n",
    "    problem_sizes += [p_size]\n",
    "\n",
    "problem_sizes = []\n",
    "\n",
    "for mod in model.modules():\n",
    "    if isinstance(mod, torch.nn.Conv2d) and mod.groups == mod.in_channels:\n",
    "        mod.register_forward_hook(partial(hook, problem_sizes=problem_sizes))\n",
    "\n",
    "model(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_forward, conv2d_backward\n",
    "\n",
    "class Conv2dFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights, padding):\n",
    "        h_pad, w_pad = padding\n",
    "        outputs = conv2d_forward(inputs, weights, h_pad)\n",
    "        ctx.padding = padding\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dout):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        dout = dout.contiguous()\n",
    "        assert inputs.is_contiguous() and weights.is_contiguous()\n",
    "\n",
    "        h_pad, w_pad = ctx.padding\n",
    "        din, dweights = conv2d_backward(dout, inputs, weights, h_pad)\n",
    "\n",
    "        return din, dweights, None\n",
    "\n",
    "\n",
    "class CustomDepthwiseConv2d(nn.Conv2d):\n",
    "    def forward(self, x):\n",
    "        return Conv2dFunc.apply(x, self.weight, self.padding)\n",
    "    \n",
    "def run(layer, x):\n",
    "    layer.weight.grad = None\n",
    "    x.grad = None\n",
    "    y = layer(x)\n",
    "    y.mean().backward()\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "def test(p_size, n=32, atol=1e-7):\n",
    "    _, num_channels, h, w, kernel_size, _ = p_size\n",
    "\n",
    "    custom_layer = CustomDepthwiseConv2d(\n",
    "        num_channels,\n",
    "        num_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=kernel_size // 2,\n",
    "        groups=num_channels,\n",
    "        bias=False,\n",
    "    ).cuda()\n",
    "\n",
    "    torch_layer = nn.Conv2d(\n",
    "        num_channels,\n",
    "        num_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=kernel_size // 2,\n",
    "        groups=num_channels,\n",
    "        bias=False,\n",
    "    ).cuda()\n",
    "    torch_layer.load_state_dict(custom_layer.state_dict())\n",
    "\n",
    "    tmp = dict()\n",
    "    def hook(mod, grad_in, grad_out):\n",
    "        tmp[\"grad_out\"] = grad_out\n",
    "\n",
    "    torch_layer.register_backward_hook(hook)\n",
    "\n",
    "    x1 = torch.randn([n, num_channels, h, w]).cuda()\n",
    "    x2 = x1.clone()\n",
    "\n",
    "    x1.requires_grad_(True)\n",
    "    x2.requires_grad_(True)\n",
    "\n",
    "    # Exectue\n",
    "    y1 = custom_layer(x1)\n",
    "    y2 = torch_layer(x2)\n",
    "    y1.exp().sum().backward()\n",
    "    y2.exp().sum().backward()\n",
    "\n",
    "    max_error_y = (y1 - y2).abs().max()\n",
    "    assert torch.allclose(y1, y2, atol=atol)\n",
    "\n",
    "    max_error_din = (x1.grad - x2.grad).abs().max()\n",
    "    assert torch.allclose(x1.grad, x2.grad, atol=atol)\n",
    "\n",
    "    max_error_dw = (custom_layer.weight.grad - torch_layer.weight.grad).abs().max()\n",
    "    assert torch.allclose(custom_layer.weight.grad, torch_layer.weight.grad, atol=atol)\n",
    "\n",
    "    print(f\"P: {p_size}, max_error_y={max_error_y}, max_error_din={max_error_din}, max_error_dw={max_error_dw}\")\n",
    "\n",
    "    return custom_layer, torch_layer, x1, x2, tmp[\"grad_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinnamkim/flash-fft-conv/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkip kernel_size != 3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m custom_layer, torch_layer, x1, x2, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun(custom_layer, x1)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun(torch_layer, x2)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 82\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(p_size, n, atol)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(y1, y2)\n\u001b[1;32m     81\u001b[0m max_error_din \u001b[38;5;241m=\u001b[39m (x1\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m-\u001b[39m x2\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(x1\u001b[38;5;241m.\u001b[39mgrad, x2\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m     84\u001b[0m max_error_dw \u001b[38;5;241m=\u001b[39m (custom_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m-\u001b[39m torch_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(custom_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad, torch_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p_size in problem_sizes:\n",
    "    kernel_size = p_size[-1]\n",
    "\n",
    "    if kernel_size != 3:\n",
    "        print(f\"Skip kernel_size != 3: {p_size}\")\n",
    "        continue\n",
    "\n",
    "    custom_layer, torch_layer, x1, x2, _ = test(p_size, n=64, atol=1e-3)\n",
    "    %timeit run(custom_layer, x1)\n",
    "    %timeit run(torch_layer, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(32, 32, kernel_size=3, padding=1, groups=32, bias=False),\n",
    "    nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
    ").cuda()\n",
    "\n",
    "x = torch.randn([1, 32, 64, 64], requires_grad=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinnamkim/flash-fft-conv/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    if param.grad is not None:\n",
    "        param.grad.data.fill_(0.0)\n",
    "\n",
    "y = model(x)\n",
    "y.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_forward\n",
    "\n",
    "n, num_channels, h, w = 32, 16, 112, 112\n",
    "#n, num_channels, h, w = 16, 960, 7, 7\n",
    "n, num_channels, h, w = 32, 240, 28, 28\n",
    "# n = 4\n",
    "# num_channels = 512\n",
    "# h = w = 64\n",
    "\n",
    "depthwise_conv2d = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, groups=num_channels, bias=False).cuda()\n",
    "x = torch.randn([n, num_channels, h, w], requires_grad=False).cuda()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run():\n",
    "    y = depthwise_conv2d(x)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "y = run()\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_my():\n",
    "    y = conv2d_forward(x, depthwise_conv2d.weight.contiguous(), 1)\n",
    "    torch.cuda.synchronize()\n",
    "    return y\n",
    "\n",
    "z = run_my()\n",
    "\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 ms ± 61.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run_my()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 ms ± 8.97 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grad_input': (tensor([[[[-0.2183,  0.2789,  0.0979],\n",
      "          [-0.1423, -0.4692, -0.1749],\n",
      "          [-0.1839, -0.2082, -0.1159]],\n",
      "\n",
      "         [[-0.7890, -1.3427, -0.4157],\n",
      "          [ 0.0278, -1.2945, -0.7607],\n",
      "          [-0.1968, -0.4257, -0.1693]]]], device='cuda:0'),), 'grad_output': (tensor([[[[0.9344, 1.0868, 0.6731],\n",
      "          [0.8925, 0.6576, 1.3336],\n",
      "          [1.1533, 0.8259, 0.7464]],\n",
      "\n",
      "         [[2.2257, 0.8318, 0.8736],\n",
      "          [0.9656, 1.8273, 1.8586],\n",
      "          [0.7153, 0.4761, 1.3053]]]], device='cuda:0'),)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from monarch_cuda import conv2d_backward\n",
    "\n",
    "torch.manual_seed(3003)\n",
    "\n",
    "# n, num_channels, h, w = 32, 16, 112, 112\n",
    "#n, num_channels, h, w = 16, 960, 7, 7\n",
    "# n, num_channels, h, w = 32, 240, 28, 28\n",
    "n, num_channels, h, w = 1, 2, 3, 3\n",
    "# n = 4\n",
    "# num_channels = 512\n",
    "# h = w = 64\n",
    "\n",
    "depthwise_conv2d = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, groups=num_channels, bias=False).cuda()\n",
    "x = torch.randn([n, num_channels, h, w], requires_grad=True).cuda()\n",
    "\n",
    "states = {}\n",
    "def log_bwd(module, grad_input, grad_output):\n",
    "    states[\"grad_input\"] = grad_input\n",
    "    states[\"grad_output\"] = grad_output\n",
    "\n",
    "depthwise_conv2d.register_full_backward_hook(log_bwd)\n",
    "\n",
    "y = depthwise_conv2d(x)\n",
    "y.exp().sum().backward()\n",
    "\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.4781,  2.4529,  1.5677],\n",
      "          [ 3.4162,  5.0975,  2.0699],\n",
      "          [ 3.4967,  3.3039,  1.2509]]],\n",
      "\n",
      "\n",
      "        [[[-4.0330, -2.7529, -1.1068],\n",
      "          [-0.8394, -3.9504, -2.7955],\n",
      "          [-1.0433,  4.1894,  0.8581]]]], device='cuda:0')\n",
      "tensor([[[[ 2.4781,  2.4529,  1.5677],\n",
      "          [ 3.4162,  5.0975,  2.0699],\n",
      "          [ 3.4967,  3.3039,  1.2509]]],\n",
      "\n",
      "\n",
      "        [[[-4.0330, -2.7529, -1.1068],\n",
      "          [-0.8394, -3.9504, -2.7955],\n",
      "          [-1.0433,  4.1894,  0.8581]]]], device='cuda:0')\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    din, dweights = conv2d_backward(states[\"grad_output\"][0], x.clone(), depthwise_conv2d.weight, 1)\n",
    "# print(din)\n",
    "# print(states)\n",
    "# print(din.shape)\n",
    "print(dweights)\n",
    "print(depthwise_conv2d.weight.grad.data)\n",
    "# print(dweights.shape)\n",
    "print(torch.allclose(states[\"grad_input\"][0], din))\n",
    "print(torch.allclose(depthwise_conv2d.weight.grad.data, dweights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.6256, 12.1385, -4.9606],\n",
      "          [ 0.3313,  0.0327, -4.5083],\n",
      "          [ 2.0863,  2.7183, 11.1900]]],\n",
      "\n",
      "\n",
      "        [[[-0.1741,  7.9010, -0.5848],\n",
      "          [ 1.1680,  9.1308, -1.7229],\n",
      "          [ 1.8568,  3.9883, -6.0307]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(depthwise_conv2d.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.3339, 0.6068, 1.4437, 0.4591, 3.2536],\n",
       "          [0.4609, 0.8319, 1.2438, 1.3593, 0.4581],\n",
       "          [3.2788, 1.1048, 1.0025, 0.9150, 0.8091],\n",
       "          [0.5265, 2.7995, 1.8639, 1.1154, 1.9408],\n",
       "          [1.0752, 0.4621, 0.7071, 0.9627, 0.6054]],\n",
       "\n",
       "         [[0.9014, 2.2644, 1.0638, 0.7618, 1.0463],\n",
       "          [0.4676, 3.2272, 1.1820, 0.8296, 3.7058],\n",
       "          [0.9902, 1.6993, 0.2760, 1.1363, 3.5201],\n",
       "          [0.7246, 0.8807, 0.8306, 1.5082, 1.4903],\n",
       "          [0.9297, 2.2455, 1.0649, 0.8699, 1.2829]]]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[\"grad_output\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.3243,  0.2552,  0.0164,  0.2652, -0.7573],\n",
       "           [ 0.9317,  0.1859,  0.2556,  0.3482,  1.0515],\n",
       "           [-0.5501,  1.2759,  0.7390,  0.3441,  0.0424],\n",
       "           [ 0.8952, -1.3240,  0.2384,  0.2251, -0.2865],\n",
       "           [ 0.2867,  0.9382, -0.4277, -0.1551,  0.1596]],\n",
       " \n",
       "          [[ 0.7385, -0.4478, -0.8459, -0.0750, -0.9847],\n",
       "           [ 1.1138, -0.2448, -0.7152,  0.7494, -0.9785],\n",
       "           [ 1.1503, -0.8641, -0.2171,  1.4930, -1.4552],\n",
       "           [ 0.3670, -0.7512,  0.2272,  0.7006, -1.5908],\n",
       "           [ 0.7140,  0.2325, -0.1341,  0.1210, -0.4547]]]], device='cuda:0'),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[\"grad_input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
